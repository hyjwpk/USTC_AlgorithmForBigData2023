# 聚类划分

聚类划分的主要目标是：将数据集 $A$ 划分成 $k$ 个不相交的子集 $C_1, C_2, \cdots, C_k$，满足同一个子集中的点距离比较近，不同子集中的点距离比较远。这时我们将这 $k$ 个子集称为 $k$ 个聚类。这个目标非常宽泛，后文将给出细化解释

## 基于中心的聚类划分

### $k-$均值/中值/中心

给定 $\R^d$ 中包含 $n$ 个点的数据集 $A$，度量函数 $D$（例如 $D$ 可以取二范数 $D(\vec x,\vec y) = \norm{\vec x -\vec y}_2$）与参数 $q\geq 1, k\in\N_+$，基于中心的聚类划分可以被描述为：找到 $k$ 个中心点 $\vec c_1,\vec c_2, \cdots,\vec c_k\in\R^d$，使得 $\sum_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})^q$ 最小，其中 $C$ 是点集的时候 $D(\vec a, C)\triangleq \min_{\vec c\in C}D(\vec a, \vec c)$，也就是 $\vec a$ 到 $C$ 中点距离的最小值

* 当 $q = 1$ 的时候，目标函数为最小化 $\sum_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})$，被称为 **$k-$中值 ($k-$median)**
* 当 $q = 2$ 的时候，目标函数为最小化 $\sum_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})^2$，被称为 **$k-$均值 ($k-$means)**
* 当 $q \to\infty$ 的时候，目标函数为最小化 $\max_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})$，被称为 **$k-$中心 ($k-$center)**

> $k-$中心的目标函数是这样得出的：最小化 $\sum_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})^q$ 等价于最小化 $\qty(\sum_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})^q)^{\frac 1q}$。当 $q\to\infty$ 的时候，后者就等价于 $\max_{i = 1}^nD(\vec a_i, \set{\vec c_1, \cdots, \vec c_k})$

对于数据集 $A$，上文定义了目标函数来衡量某 $k$ 个中心点的优劣。当找到了某个目标函数下最优的中心点后，我们将 $A$ 划分成 $k$ 个聚类的无交并 $C_1\sqcup \cdots\sqcup C_k$，满足 $\vec a\in C_i\implies D(\vec a, \vec c_i) \leq D(\vec a, \vec c_j)\forall j = 1, 2, \cdots, n$ 即可

> 如果有 $\vec a$ 到中心点 $\vec c_i$ 与 $\vec c_j$ 的距离一样近，我们既可以将其放进聚类 $C_i$ 也可以将其放进聚类 $C_j$

### Lloyd 算法 - $k-$均值聚类划分算法

对于欧式距离 $D(\vec x, \vec y) = \norm{x - y}_2$，输入数据集 $A\subset \R^d$ 与聚类数目 $k\in\N_+$，Lloyd 算法可以被描述成：

1. 随意地选择 $\vec c_1, \cdots, \vec c_k\in\R^d$
2. 重复如下两步，直到 $\vec c_1, \cdots, \vec c_k$ 不再改变：
   1. 对于 $i = 1, 2, \cdots, n$，如果点 $\vec a_i$ 所在聚类的中心不是与其最近的中心，那么就取出 $\vec a_i$ 并将其放在其最近的中心点所对应的聚类中
   2. 对于 $i = 1, 2, \cdots, k$，将中心点 $\vec c_i$ 改为 $C_i$ 的重心 $\vec g(C_i)\triangleq \frac 1{\abs{C_i}}\sum_{\vec a\in C_i}\vec a$
3. 返回 $k$ 个中心点 $\vec c_1, \cdots, \vec c_k$ 与 $k$ 个聚类 $C_1\sqcup \cdots\sqcup C_k$

Lloyd 算法不能保证得到最优解，但是从直观上能得到一个比较好的解，因为以下引理保证了当 $k = 1$ 的时候 Lloyd 算法一定可以得到最优解

**引理：**对于任意的 $\vec x\in\R^d$ 与有限集 $A\subset \R^d$，设 $\vec g(A')\triangleq \frac 1{\abs{A'}}\sum_{\vec a\in A'}\vec a$ 被定义为数据集 $A'$ 的重心
$$
\sum_{\vec a\in A'}\norm{\vec a - \vec x}_2^2 = \sum_{\vec a\in A'}\norm{\vec a - \vec g(A')} + \abs{A'}\norm{\vec g(A') - \vec x}
$$
**证明：**首先由 $\vec c(A') = \frac 1{\abs{A'}}\sum_{\vec a\in A'}\vec a$ 的定义可以得知 $\sum_{\vec a\in A'}\vec a - \abs{A'}\vec c(A') = \vec 0$，也就是 $\sum_{\vec a\in A'}(\vec a - \vec c(A')) = \vec 0$。所以
$$
\begin{aligned}
\sum_{\vec a\in A'}\norm{\vec a - \vec x}_2^2 &= \sum_{\vec a\in A'}
\qty(\norm{\vec a - \vec g(A')}_2^2 + \norm{\vec g(A') - \vec x}_2^2 + 2(\vec g(A') - \vec x)^\intercal(\vec a - \vec g(A')))\\
&= \sum_{\vec a\in A'}\norm{\vec a - \vec g(A')}_2^2 + \abs{A'}\norm{\vec g(A') - \vec x}_2^2 + 2(\vec g(A') - \vec x)^\intercal \sum_{\vec a\in A'}(\vec a - \vec g(A'))\\
&= \sum_{\vec a\in A'}\norm{\vec a - \vec g(A')}_2^2 + \abs{A'}\norm{\vec g(A') - \vec x}_2^2 + 2(\vec g(A') - \vec x)^\intercal \cdot \vec 0\\
&= \sum_{\vec a\in A'}\norm{\vec a - \vec g(A')}_2^2 + \abs{A'} \norm{\vec g(A') - \vec x}_2^2
\end{aligned}
$$

<hr>

由二范数的正定性知 $\norm{\vec g(A') - \vec x}_2^2\geq 0$，这也就表明 $\sum_{\vec a\in A'}\norm{\vec a - \vec x}_2^2\geq \sum_{\vec a\in A'}\norm{\vec a - \vec g(A)}_2^2$，说明当 $k = 1$ 的时候 $k-$means 中心就是点集的重心

接下来讨论 Lloyd 算法的性能。在这里我们能给出

**定理：**Lloyd 算法可以在有限步内运行结束

**证明：**首先注意到将 $n$ 个点划分成 $k$ 个（非空）聚类的方案数不超过 $n^k$，所以方案数是有限的。设有 $m$ 种将 $n$ 个结点划分为 $k$ 个（非空）聚类的方案 $\mathcal C_1, \mathcal C_2, \cdots, \mathcal C_m$

在每次循环结束时，Lloyd 算法的 $k$ 个中心点 $\vec c_1, \vec c_2, \cdots, \vec c_k$ 的位置完全是由这 $k$ 个聚类的性质而定的，因为循环的第二步会对每个 $i = 1, 2, \cdots, k$ 将 $\vec c_i$ 设置成聚类 $C_i$ 的重心。设聚类划分方案 $\mathcal C = \set{C_1, C_2, \cdots, C_k}$ 的权值为聚类中心 $\vec c_i$ 为 $C_i$ 重心 $\vec g(C_i)$ 时的 $k-$均值权值（也就是 $\sum_{i = 1}^n D(\vec a_i, \set{\vec g(C_1), \vec g(C_2), \cdots, \vec g(C_k)})^2$），再按照该权值将这 $m$ 个聚类划分方案从小到大排序为  $\mathcal C^{[1]}, \mathcal C^{[2]}, \cdots, \mathcal C^{[m]}$，那么 $\mathcal C^{[i]}$ 的权值小于 $\mathcal C^{[j]}$ 的权值可以推出 $i < j$

每次循环结束时当前的聚类划分方案一定是这 $m$ 个中的一种，设第 $i$ 次迭代结束时的聚类划分方案是 $\mathcal C^{[t_i]}$。在没有收敛的时候，迭代的第 1 步会让目标函数变小，而迭代的第 2 步不会让目标函数变大，所以每次迭代会严格让目标函数变小，这意味着 $t_1 > t_2 > \cdots$

显然 $\set{t_i}$ 是一个自然数序列，所以 $t_2\leq t_1 - 1, t_3\leq t_2 - 1\leq t_1 - 2$，以此类推，这表明 Lloyd 算法的迭代次数必不可能大于 $t_1\leq m\leq n^k$。算法一定在有限的次数内迭代完成